{"name":"Practical-machine-learning","tagline":"Course Project","body":"---\r\ntitle: \"PracticalMachineLearning\"\r\nauthor: \"JFlanagan\"\r\ndate: \"Saturday, October 25, 2014\"\r\noutput: html_document\r\n---\r\n\r\n##Practical Machine Learning from www.coursera.org\r\n###Course Project\r\n\r\nThe objective of this project is to develop a predictive model to predict the quality of barbell lifts using  data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants, who were requested to perform barbell lifts correctly and incorrectly in 5 different ways. \r\n\r\nThe steps undertaken in this project were:\r\n\r\n1. Import training data\r\n2. Tidy data (removal of NAs and non-predictive information)\r\n3. Split data 70/30 for the purposes of model building and cross-validation\r\n4. Apply different predictive models and assess accuracy based on \"Out of Sample Error\"\r\n5. Import test data and tidy in the same manner as the training data\r\n6. Apply predictive model which gave best results in step 4.\r\n\r\n###Step 1. Import training data\r\n```{r, cache=TRUE}\r\ntrainingraw <- read.csv(\"C:/Users/mikoflan/Documents/PredMachLearning/pml-training.csv\", \r\n                          na.strings= c(\"NA\",\"\",\" \"))\r\n```\r\n###Step 2. Tidy data (removal of NAs and non-predictive information)\r\nFirst, I computed the number of missing values per column of data. Then I investigated the occurence of NAs; the results showed that columns either contained >15,000 NAs or no NAs. In a dataset with 19,622 observations, I decided that if there were in excess of 15,000 NAs, these columns added little predictive power to the model chosen.\r\n\r\n```{r, cache=TRUE}\r\ndim(trainingraw)\r\ntrainingrawNA <- apply(trainingraw, 2, function(x) sum(is.na(x)))\r\n\r\nsum(trainingrawNA > 10)\r\nsum(trainingrawNA > 15000)\r\nsum(trainingrawNA > 0) ## therefore can remove all cols with any NA (if one NA, then > 10000 NAs)\r\n\r\ntraining <- trainingraw[,which(trainingrawNA < 1)]\r\n\r\nncoltraining <- ncol(training)\r\ntraining <- training[,8:ncoltraining] ##remove non-predictive information in 1st 8 columns\r\ntable(training$classe) ## get overview of outcome\r\n```\r\n###Step 3. Split data 70/30 for the purposes of model building and cross-validation\r\n```{r, cache=TRUE}\r\nlibrary(caret)\r\ninTrain <- createDataPartition(y = training$classe, p = 0.7, list = FALSE)\r\ntrain <- training[inTrain, ]\r\ncrossval <- training[-inTrain, ]\r\n\r\nlibrary(corrplot)\r\ntrain2 <- train[,-53]\r\nM <- cor(train2)\r\ncorrplot(M, type=\"lower\", order=\"hclust\") ## visualize potential correlations\r\n```\r\n\r\n###Step 4. Apply different predictive models and assess accuracy based on \"Out of Sample Error\"\r\n\r\nI would like to Out of Sample Error rate of less than 5 %.\r\n\r\n4a. Linear Discriminant Analysis\r\n```{r, cache=TRUE}\r\nmodlda <- train(classe ~ ., data=train, method = \"lda\")\r\nplda <- predict(modlda, crossval)\r\nconfusionMatrix(crossval$classe, plda) ## 70.28% accuracy\r\nOOSE.acc.lda <- sum(plda == crossval$classe)/length(plda)\r\nOOSE.lda <- round(((1-OOSE.acc.lda)*100), digits=2)\r\n```\r\nThe Out of Sample Error using Linear Discriminant Analysis was estimated to be `r OOSE.lda`%.\r\n\r\n4b. Classification tree\r\n```{r, cache=TRUE}\r\nlibrary(rpart)\r\nmodrpart <- train(classe ~., method=\"rpart\", data=train)\r\npredrpart <- predict(modrpart, crossval)\r\nconfusionMatrix(crossval$classe, predrpart) ##49% accuracy\r\nOOSE.acc.rpart <- sum(predrpart == crossval$classe)/length(predrpart)\r\nOOSE.rpart <- round(((1-OOSE.acc.rpart)*100), digits=2)\r\n```\r\nThe Out of Sample Error using the Classification tree method was estimated to be `r OOSE.rpart`%.\r\n\r\n4c. Random Forest\r\n```{r, cache=TRUE}\r\nlibrary(randomForest)\r\nmodel <- randomForest(classe ~ ., data = train)\r\npredCrossVal <- predict(model, crossval)\r\nconfusionMatrix(crossval$classe, predCrossVal) ## 99.4% accuracy\r\nOOSE.acc.rf <- sum(predCrossVal == crossval$classe)/length(predCrossVal)\r\nOOSE.rf <- round(((1-OOSE.acc.rf)*100), digits=2)\r\n```\r\nThe Out of Sample Error using the Random Forest method was estimated to be `r OOSE.rf`%.\r\n\r\nAs this was by far the most accurate of the 3 methods tested, and below the desired level of 5 %, I decided to use this model for the test data.\r\n\r\n###Step 5. Import test data and tidy in the same manner as the training data\r\n```{r, cache=TRUE}\r\ntestingraw <- read.csv(\"C:/Users/mikoflan/Documents/PredMachLearning/pml-testing.csv\", \r\n                       na.strings= c(\"NA\",\"\",\" \"))\r\ntestingrawNA <- apply(testingraw, 2, function(x) sum(is.na(x)))\r\n\r\nsum(testingrawNA > 10)\r\nsum(testingrawNA > 15000)\r\nsum(testingrawNA > 0) ## therefore can remove all cols with any NA (if one NA, then > 15000 NAs)\r\n\r\ntesting <- testingraw[,which(testingrawNA < 1)]\r\n\r\nncoltesting <- ncol(testing)\r\ntesting <- testing[,8:ncoltesting] ##remove non-predictive information in 1st 8 columns\r\n```\r\n###Step 6. Apply predictive model which gave best results in step 4.\r\n```{r, cache=TRUE}\r\npredicttesting <- predict(model, testing)\r\n```","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}